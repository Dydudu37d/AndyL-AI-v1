import os
import logging
import threading
import tempfile
import pygame
import requests
import json
import time
import asyncio
import socket
import comtypes.client  # ç”¨äºWindowsè¯­éŸ³API
import re
import numpy as np
import torch
import torch.nn as nn
from typing import Optional, Callable, Dict, Any
from ai_brain import OllamaDeepSeekClient, AIBrain, VTuberPersona
from obs import OBSController
from dotenv import load_dotenv
import edge_tts  # ç”¨äºEdge TTS
from interactive_obs_text_tool import *

# ç¡®ä¿ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸
import matplotlib.pyplot as plt
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("TTSSpeaker")

def get_local_ip():
    try:
        # å»ºç«‹ä¸€ä¸ªä¸´æ—¶çš„UDPè¿æ¥åˆ°Googleçš„DNSæœåŠ¡å™¨
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(('8.8.8.8', 80))
        # è·å–è¿æ¥çš„æœ¬åœ°IPåœ°å€
        ip = s.getsockname()[0]
        s.close()
        return ip
    except Exception as e:
        return f"è·å–IPæ—¶å‡ºé”™: {e}"

local_ip = get_local_ip()
print(f"æœ¬æœºå†…ç½‘IP: {local_ip}")
host = input("è¯·è¾“å…¥OBS WebSocketæœåŠ¡å™¨åœ°å€ (é»˜è®¤: 192.168.0.186): ") or local_ip

# OBSæ§åˆ¶å™¨é…ç½®
obs_controller = OBSController(
    host=host,
    port=4455,
    password='gR7UXLWyqEBaRd2S'
)

textAI = OBSTextTool()

# é«˜çº§ç¥ç»è¯­éŸ³åˆæˆæ¨¡å‹
class AdvancedVoiceModel(nn.Module):
    """æ”¹è¿›çš„è¯­éŸ³åˆæˆç¥ç»ç½‘ç»œæ¨¡å‹"""
    def __init__(self, embedding_dim=256, hidden_dim=512, output_dim=16000):
        super(AdvancedVoiceModel, self).__init__()
        # æ–‡æœ¬åµŒå…¥å±‚ï¼ˆå‡è®¾ä½¿ç”¨ç®€å•çš„å­—ç¬¦åµŒå…¥ï¼‰
        self.char_embedding = nn.Embedding(10000, embedding_dim)  # å‡è®¾ä½¿ç”¨10000ä¸ªå­—ç¬¦çš„è¯æ±‡è¡¨
        
        # LSTMå±‚å¤„ç†æ–‡æœ¬åºåˆ—
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)
        
        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.MultiheadAttention(hidden_dim * 2, num_heads=4, batch_first=True)
        
        # è§£ç å™¨ç½‘ç»œï¼ˆå°†æ–‡æœ¬ç‰¹å¾è½¬æ¢ä¸ºéŸ³é¢‘ç‰¹å¾ï¼‰
        self.decoder = nn.Sequential(
            nn.Linear(hidden_dim * 2, 1024),
            nn.ReLU(),
            nn.BatchNorm1d(1024),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Linear(256, output_dim)  # è¾“å‡ºéŸ³é¢‘æ ·æœ¬
        )
        
        # è¾“å‡ºå¤„ç†å±‚
        self.output_processor = nn.Sequential(
            nn.Conv1d(1, 16, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv1d(32, 1, kernel_size=1)
        )
        
        self._initialize_weights()
        
    def _initialize_weights(self):
        """åˆå§‹åŒ–æ¨¡å‹æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.LSTM):
                for name, param in m.named_parameters():
                    if 'weight' in name:
                        nn.init.kaiming_normal_(param)
                    elif 'bias' in name:
                        nn.init.zeros_(param)
    
    def forward(self, text_features, sequence_lengths=None):
        # å¤„ç†æ–‡æœ¬åµŒå…¥
        embedded = self.char_embedding(text_features)
        
        # LSTMå¤„ç†
        if sequence_lengths is not None:
            # å¯¹å˜é•¿åºåˆ—è¿›è¡Œpackæ“ä½œ
            packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sequence_lengths, batch_first=True, enforce_sorted=False)
            packed_output, (h_n, c_n) = self.lstm(packed_embedded)
            # å¯¹è¾“å‡ºè¿›è¡Œunpackæ“ä½œ
            lstm_output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)
        else:
            lstm_output, (h_n, c_n) = self.lstm(embedded)
        
        # æ³¨æ„åŠ›æœºåˆ¶
        attn_output, _ = self.attention(lstm_output, lstm_output, lstm_output)
        
        # å…¨å±€æ± åŒ–ï¼Œå°†åºåˆ—ç‰¹å¾è½¬æ¢ä¸ºå›ºå®šé•¿åº¦ç‰¹å¾
        global_features = torch.mean(attn_output, dim=1)
        
        # è§£ç å±‚ç”ŸæˆéŸ³é¢‘ç‰¹å¾
        audio_features = self.decoder(global_features)
        
        # è¿›ä¸€æ­¥å¤„ç†éŸ³é¢‘ç‰¹å¾ä»¥æé«˜è´¨é‡
        audio_features = audio_features.unsqueeze(1)  # æ·»åŠ é€šé“ç»´åº¦ [batch, 1, output_dim]
        processed_audio = self.output_processor(audio_features)
        processed_audio = processed_audio.squeeze(1)  # ç§»é™¤é€šé“ç»´åº¦
        
        return processed_audio

# æ–‡æœ¬å¤„ç†å™¨
class TextProcessor:
    """å¤„ç†æ–‡æœ¬è¾“å…¥ï¼Œå°†å…¶è½¬æ¢ä¸ºæ¨¡å‹å¯å¤„ç†çš„ç‰¹å¾"""
    def __init__(self):
        # åŸºæœ¬ä¸­æ–‡å­—ç¬¦æ˜ å°„ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨æ›´å®Œæ•´çš„æ˜ å°„è¡¨ï¼‰
        self.char_to_idx = self._build_basic_vocab()
        self.max_text_length = 200  # æœ€å¤§æ–‡æœ¬é•¿åº¦
        
    def _build_basic_vocab(self):
        """æ„å»ºåŸºæœ¬è¯æ±‡è¡¨"""
        # åŸºæœ¬ASCIIå­—ç¬¦
        vocab = {chr(i): i + 1 for i in range(32, 127)}  # 1-95
        
        # æ·»åŠ å¸¸ç”¨ä¸­æ–‡å­—ç¬¦ï¼ˆç¤ºä¾‹ï¼‰
        common_chinese = "ä½ å¥½æˆ‘æ˜¯åœ¨è¿™æœ‰ä¸ªäººä»¬çš„ä¸€äº†ä¸å¾ˆè¿™æ˜¯ä¸ªå¤§ä¸­å›½åŒ—äº¬ä¸Šæµ·å¹¿å·æ·±åœ³å¤©å—æµ·åŒ—"
        start_idx = 100
        for char in common_chinese:
            if char not in vocab:
                vocab[char] = start_idx
                start_idx += 1
        
        # æ·»åŠ ç‰¹æ®Šæ ‡è®°
        vocab['<UNK>'] = 0  # æœªçŸ¥å­—ç¬¦
        vocab['<PAD>'] = start_idx  # å¡«å……å­—ç¬¦
        
        return vocab
    
    def text_to_features(self, text):
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯å¤„ç†çš„ç‰¹å¾"""
        # è¿‡æ»¤æ–‡æœ¬
        filtered_text = self._filter_text(text)
        
        # å°†æ–‡æœ¬è½¬æ¢ä¸ºç´¢å¼•åºåˆ—
        features = []
        for char in filtered_text:
            # æˆªå–æœ€å¤§é•¿åº¦
            if len(features) >= self.max_text_length:
                break
            
            # è½¬æ¢å­—ç¬¦åˆ°ç´¢å¼•
            if char in self.char_to_idx:
                features.append(self.char_to_idx[char])
            else:
                features.append(self.char_to_idx['<UNK>'])  # æœªçŸ¥å­—ç¬¦
        
        # å¡«å……åˆ°æœ€å¤§é•¿åº¦
        if len(features) < self.max_text_length:
            pad_length = self.max_text_length - len(features)
            features.extend([self.char_to_idx['<PAD>']] * pad_length)
        
        return torch.tensor(features, dtype=torch.long).unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    
    def _filter_text(self, text):
        """è¿‡æ»¤æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        # ä¿ç•™ä¸­æ–‡å­—ç¬¦ã€è‹±æ–‡å’ŒåŸºæœ¬æ ‡ç‚¹
        filtered = re.sub(r'[^ä¸€-é¾¥a-zA-Z0-9ï¼Œã€‚ï¼ï¼Ÿ,.!?]', '', text)
        return filtered.strip()

# éŸ³é¢‘å¤„ç†å™¨
class AudioProcessor:
    """å¤„ç†éŸ³é¢‘æ•°æ®ï¼ŒåŒ…æ‹¬ç”Ÿæˆã€å¢å¼ºå’Œä¿å­˜"""
    def __init__(self, sample_rate=16000):
        self.sample_rate = sample_rate
        
    def process_audio(self, audio_data):
        """å¤„ç†æ¨¡å‹ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®"""
        # ç¡®ä¿éŸ³é¢‘æ•°æ®å½¢çŠ¶æ­£ç¡®
        if len(audio_data.shape) == 1:
            audio_data = audio_data.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        audio_np = audio_data.detach().cpu().numpy().flatten()
        
        # å½’ä¸€åŒ–éŸ³é¢‘
        max_val = np.max(np.abs(audio_np))
        if max_val > 0:
            audio_np = audio_np / max_val
        
        # æ·»åŠ ç®€å•çš„éŸ³é¢‘å¢å¼º
        audio_np = self._enhance_audio(audio_np)
        
        # è½¬æ¢ä¸º16ä½æ•´æ•°
        audio_np = np.int16(audio_np * 32767)
        
        return audio_np
    
    def _enhance_audio(self, audio_data):
        """ç®€å•çš„éŸ³é¢‘å¢å¼º"""
        # æ·»åŠ è½»å¾®çš„é¢„åŠ é‡ï¼ˆé«˜é¢‘å¢å¼ºï¼‰
        pre_emphasis = 0.97
        enhanced = np.append(audio_data[0], audio_data[1:] - pre_emphasis * audio_data[:-1])
        
        # è½»å¾®çš„éŸ³é‡å½’ä¸€åŒ–
        max_amplitude = np.max(np.abs(enhanced))
        if max_amplitude > 0:
            enhanced = enhanced * 0.9 / max_amplitude
        
        return enhanced
    
    def save_to_wav(self, audio_data, output_file):
        """ä¿å­˜éŸ³é¢‘æ•°æ®ä¸ºWAVæ–‡ä»¶"""
        import wave
        
        with wave.open(output_file, 'wb') as wf:
            wf.setnchannels(1)  # å•å£°é“
            wf.setsampwidth(2)  # 16ä½
            wf.setframerate(self.sample_rate)
            wf.writeframes(audio_data.tobytes())
            
        return output_file


class TTSSpeaker:
    """TTSè¯­éŸ³åˆæˆå™¨ï¼Œæ”¯æŒWindowIå’ŒLocalAI TTS(å·²å»¢æ£„)"""
    
    def __init__(self):
        self.is_initialized = False
        self.voice_engine = None
        self.current_voice = None
        self._is_speaking = False
        self._lock = threading.Lock()
        self._tts_type = os.getenv("TTS_TYPE", "edge")  # windows, localai, edge æˆ– custom
        
        # LocalAIé…ç½® (å·²å»¢æ£„)
        self.localai_host = os.getenv("LOCALAI_HOST", "localhost")
        self.localai_port = os.getenv("LOCALAI_PORT", "8080")
        self.localai_tts_model = os.getenv("LOCALAI_TTS_MODEL", "tts-1")
        self.localai_tts_voice = os.getenv("LOCALAI_TTS_VOICE", "alloy")
        
        # Edge TTSé…ç½®
        self.edge_tts_voice = os.getenv("EDGE_TTS_VOICE", "zh-CN-XiaoxiaoNeural")
        self.edge_tts_rate = os.getenv("EDGE_TTS_RATE", "+0%")
        self.edge_tts_volume = os.getenv("EDGE_TTS_VOLUME", "+0%")
        
        # è‡ªå®šä¹‰æ¨¡å‹é…ç½®
        self.custom_model_path = os.getenv("CUSTOM_TTS_MODEL_PATH", "G:\AndyL AI v1\AndyL_AI_speak_v1\exported_voice_models\andyL_voice_model_latest.pth")
        self.custom_model = None
        self.system_prompt = AIBrain()
    
    # åˆå§‹åŒ–pygameç”¨äºæ’­æ”¾éŸ³é¢‘
    try:
        pygame.mixer.init()
    except pygame.error as e:
        logger.warning(f"åˆå§‹åŒ–pygameå¤±è´¥: {e}")
    
    def initialize(self, voice_id: str = "zh-CN-XiaoxiaoNeural") -> bool:
        """åˆå§‹åŒ–TTSå¼•æ“"""
        with self._lock:
            try:
                if self._tts_type == "localai":
                    # ä½¿ç”¨LocalAIçš„TTSæœåŠ¡
                    logger.info(f"åˆå§‹åŒ–LocalAI TTSï¼Œæ¨¡å‹: {self.localai_tts_model}")
                    # ç®€å•æµ‹è¯•è¿æ¥
                    test_result = self._test_localai_connection()
                    if test_result:
                        self.is_initialized = True
                        self.current_voice = voice_id
                        logger.info("LocalAI TTSåˆå§‹åŒ–æˆåŠŸ")
                        return True
                    else:
                        logger.error("LocalAI TTSåˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨Windowsè¯­éŸ³API")
                        self._tts_type = "windows"
                elif self._tts_type == "edge":
                    # ä½¿ç”¨Edge TTSæœåŠ¡
                    logger.info(f"åˆå§‹åŒ–Edge TTSï¼Œè¯­éŸ³: {voice_id or self.edge_tts_voice}")
                    # è®¾ç½®Edge TTSè¯­éŸ³
                    self.edge_tts_voice = voice_id or self.edge_tts_voice
                    self.is_initialized = True
                    self.current_voice = self.edge_tts_voice
                    logger.info("Edge TTSåˆå§‹åŒ–æˆåŠŸ")
                    return True
                
                # é»˜è®¤ä½¿ç”¨Windowsè¯­éŸ³API
                logger.info(f"åˆå§‹åŒ–Windowsè¯­éŸ³APIï¼Œè¯­éŸ³: {voice_id}")
                self.voice_engine = comtypes.client.CreateObject("SAPI.SpVoice")
                
                # è®¾ç½®è¯­éŸ³
                voices = self.voice_engine.GetVoices()
                for i in range(voices.Count):
                    voice = voices.Item(i)
                    if voice_id in voice.GetDescription() or i == 0:
                        self.voice_engine.Voice = voice
                        self.current_voice = voice.GetDescription()
                        break
                
                self.is_initialized = True
                logger.info(f"TTSåˆå§‹åŒ–æˆåŠŸï¼Œå½“å‰è¯­éŸ³: {self.current_voice}")
                return True
            except Exception as e:
                logger.error(f"TTSåˆå§‹åŒ–å¤±è´¥: {e}")
                self.is_initialized = False
                return False
    
    def _test_localai_connection(self) -> bool:
        """æµ‹è¯•LocalAI TTSæœåŠ¡è¿æ¥"""
        try:
            url = f"http://{self.localai_host}:{self.localai_port}/v1/audio/speech"
            headers = {'Content-Type': 'application/json'}
            data = {
                "model": self.localai_tts_model,
                "input": "æµ‹è¯•",
                "voice": self.localai_tts_voice
            }
            
            response = requests.post(url, headers=headers, data=json.dumps(data), timeout=10)
            return response.status_code == 200
        except Exception as e:
            logger.error(f"LocalAIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def filter_emojis_and_special_chars(self, text: str) -> str:
        """è¿‡æ»¤æ–‡æœ¬ä¸­çš„è¡¨æƒ…ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™ä¸­æ–‡å­—ç¬¦ã€è‹±æ–‡å’Œå…¶ä»–æ­£å¸¸æ–‡æœ¬"""
        logger.debug(f"è¿‡æ»¤å‰æ–‡æœ¬é•¿åº¦: {len(text)}å­—ç¬¦ï¼Œå†…å®¹: {text}")
        
        # å®‰å…¨ç‰ˆæœ¬: ä½¿ç”¨ç›´æ¥æ›¿æ¢çš„æ–¹å¼è¿‡æ»¤è¡¨æƒ…ç¬¦å·
        # åˆ—å‡ºå¸¸è§çš„è¡¨æƒ…ç¬¦å·è¿›è¡Œè¿‡æ»¤
        filtered_text = text
        
        # è¿‡æ»¤è¡¨æƒ…ç¬¦å·ï¼ˆé€šè¿‡ç›´æ¥æ›¿æ¢è€Œä¸æ˜¯æ­£åˆ™è¡¨è¾¾å¼èŒƒå›´ï¼‰
        emojis_to_filter = "ğŸ™ğŸ˜ŠğŸ˜€ğŸ˜ƒğŸ˜„ğŸ˜ğŸ˜‚ğŸ˜…ğŸ˜ğŸ¥°ğŸ˜˜ğŸ˜—ğŸ˜™ğŸ˜šğŸ˜‹ğŸ˜›ğŸ˜ğŸ˜œğŸœğŸ‘ŒğŸ¤ªğŸ¤¨ğŸ¤”ğŸ’ªğŸ®ğŸ§ğŸ¤“ğŸ˜ğŸ¤©ğŸ¥³ğŸ˜ğŸ˜’ğŸ˜ğŸ˜”ğŸ˜ŸğŸ˜•ğŸ™â˜¹ï¸ğŸ˜£ğŸ˜–ğŸ˜«ğŸ˜©ğŸ¥ºğŸ˜¢ğŸ˜­ğŸ˜¤ğŸ˜ ğŸ˜¡ğŸ¤¬ğŸ¤¯ğŸ˜³ğŸ¥µğŸ¥¶ğŸ˜±ğŸ˜¨ğŸ˜°ğŸ˜¥ğŸ˜“ğŸ¤—ğŸ¤”ğŸ¤­ğŸ¤«ğŸ¤¥ğŸ˜¶ğŸ˜ğŸ˜‘ğŸ˜¬ğŸ™„ğŸ˜¯ğŸ˜¦ğŸ˜§ğŸ˜®ğŸ˜²ğŸ˜´ğŸ˜ªğŸ¤¤ğŸ˜µğŸ¤ğŸ¥´ğŸ¤¢ğŸ¤®ğŸ¤§ğŸ˜·ğŸ¤’ğŸ¤•ğŸ¤‘ğŸ¤ ğŸ˜ˆğŸ‘¿ğŸ‘¹ğŸ‘ºğŸ¤¡ğŸ’©ğŸ‘»ğŸ’€â˜ ï¸ğŸ‘½ğŸ‘¾ğŸ¤–ğŸƒğŸ˜ºğŸ˜¸ğŸ˜¹ğŸ˜»ğŸ˜¼ğŸ˜½ğŸ™€ğŸ˜¿ğŸ˜¾ğŸ‰ğŸ‘‹ğŸ¤£ğŸ•ğŸ˜†ğŸ‘ğŸ“º"
        for emoji in emojis_to_filter:
            filtered_text = filtered_text.replace(emoji, '')
        
        # è¿‡æ»¤é›¶å®½å­—ç¬¦
        filtered_text = filtered_text.replace('+[+', '')  # é›¶å®½è¿æ¥ç¬¦
        filtered_text = filtered_text.replace('\u200d', '')  # é›¶å®½è¿æ¥ç¬¦
        filtered_text = filtered_text.replace('\u200b', '')  # é›¶å®½ç©ºæ ¼
        filtered_text = filtered_text.replace('\u200c', '')  # é›¶å®½éè¿æ¥ç¬¦
        filtered_text = filtered_text.replace('*', '')  # æ˜Ÿå·
        filtered_text = filtered_text.replace('+]=+', '')  # å³æ–¹æ‹¬å·
        
        # è¿‡æ»¤thinkæ ‡è®°å†…å®¹
        # æŸ¥æ‰¾å¹¶ç§»é™¤ä»¥thinkå¼€å¤´å’Œç»“å°¾çš„å†…å®¹
        filtered_text = re.sub(r'think.*?think', '', filtered_text, flags=re.DOTALL | re.IGNORECASE)
        
        # åªç§»é™¤ç‰¹å®šçš„å¯èƒ½å½±å“TTSçš„æ ‡è®°ï¼Œä½†ä¿ç•™æ­£å¸¸çš„æ–‡æœ¬å†…å®¹
        filtered_text = re.sub(r'\*\s*æ‰“å¡\s*\*|\*\s*ç¬‘å®¹å¼€æ€€\s*\*', '', filtered_text)
        
        # ç¡®ä¿è¿”å›ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡æœ¬
        result = filtered_text.strip()
        
        # æ£€æŸ¥ç»“æœ
        if not result:
            logger.warning(f"è¿‡æ»¤åæ–‡æœ¬ä¸ºç©ºï¼ŒåŸå§‹æ–‡æœ¬: {text}")
            # å¦‚æœè¿‡æ»¤åæ–‡æœ¬ä¸ºç©ºï¼Œè¿”å›åŸå§‹æ–‡æœ¬çš„å‰50ä¸ªå­—ç¬¦ï¼ˆå®‰å…¨å›é€€ï¼‰
            return text[:50].strip()
        else:
            logger.debug(f"è¿‡æ»¤åæ–‡æœ¬é•¿åº¦: {len(result)}å­—ç¬¦ï¼Œå†…å®¹: {result}")

        # ä¿ç•™ä¸­æ–‡å­—ç¬¦ã€è‹±æ–‡å’ŒåŸºæœ¬æ ‡ç‚¹
        filtered = re.sub(r'[^ä¸€-é¾¥a-zA-Z0-9ï¼Œã€‚ï¼ï¼Ÿ,.!?]', '', result)
        
        return filtered.strip()
    
    def speak(self, text: str) -> bool:
        """æ’­æ”¾æ–‡æœ¬ï¼ˆåŒæ­¥æ–¹å¼ï¼‰"""
        if not self.is_initialized:
            logger.error("TTSæœªåˆå§‹åŒ–")
            return False
        # è¿‡æ»¤è¡¨æƒ…ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦
        filtered_text = self.filter_emojis_and_special_chars(text)
        logger.debug(f"åŸå§‹æ–‡æœ¬: {text}")
        logger.debug(f"è¿‡æ»¤åæ–‡æœ¬: {filtered_text}")
        obs_controller.set_text_source_content("textai123",filtered_text)
        obs_controller.set_text_source_content("textai",filtered_text)
        textAI.text("textai",filtered_text)
        textAI.text("textai123",filtered_text)
        
        with self._lock:
            self._is_speaking = True
            try:
                if self._tts_type == "localai":
                    return self._speak_with_localai(filtered_text)
                elif self._tts_type == "edge":
                    return self._speak_with_edge_tts(filtered_text)
                elif self._tts_type == "custom":
                    return self._speak_with_custom_model(filtered_text)
                else:
                    # ä½¿ç”¨Windowsè¯­éŸ³API
                    logger.info(f"ä½¿ç”¨Windowsè¯­éŸ³APIæ’­æ”¾ï¼Œæ–‡æœ¬é•¿åº¦: {len(filtered_text)}å­—ç¬¦")
                    self.voice_engine.Speak(filtered_text)
                return True
            except Exception as e:
                logger.error(f"è¯­éŸ³æ’­æ”¾å¤±è´¥: {e}")
                # å°è¯•é™çº§åˆ°æ¨¡æ‹Ÿæ’­æ”¾
                self._simulate_speech(filtered_text)
                return False
            finally:
                self._is_speaking = False
                obs_controller.set_text_source_content("textai123","")
                obs_controller.set_text_source_content("textai","")
                textAI.text("textai","")
                textAI.text("textai123","")
    
    def _speak_with_localai(self, text: str) -> bool:
        obs_controller.set_text_source_content("textai",text)
        """ä½¿ç”¨LocalAIè¿›è¡Œè¯­éŸ³åˆæˆå¹¶æ’­æ”¾"""
        try:
            url = f"http://{self.localai_host}:{self.localai_port}/v1/audio/speech"
            headers = {'Content-Type': 'application/json'}
            data = {
                "model": self.localai_tts_model,
                "input": text,
                "voice": self.localai_tts_voice
            }
            
            # å‘é€è¯·æ±‚è·å–è¯­éŸ³
            logger.info(f"å‘LocalAIå‘é€TTSè¯·æ±‚ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}å­—ç¬¦")
            response = requests.post(url, headers=headers, data=json.dumps(data), timeout=30)
            
            if response.status_code == 200:
                # ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å¹¶æ’­æ”¾
                with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
                    temp_file.write(response.content)
                    temp_file_path = temp_file.name
                
                try:
                    # æ’­æ”¾éŸ³é¢‘
                    pygame.mixer.music.load(temp_file_path)
                    pygame.mixer.music.play()
                    
                    # ç­‰å¾…æ’­æ”¾å®Œæˆ
                    while pygame.mixer.music.get_busy():
                        time.sleep(0.1)
                    
                    return True
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_file_path):
                        try:
                            os.unlink(temp_file_path)
                        except:
                            pass
            else:
                logger.error(f"LocalAI TTSè¯·æ±‚å¤±è´¥: HTTP {response.status_code}, {response.text}")
                # å°è¯•é™çº§åˆ°Windowsè¯­éŸ³API
                self._tts_type = "windows"
                try:
                    self.voice_engine = comtypes.client.CreateObject("SAPI.SpVoice")
                    self.voice_engine.Speak(text)
                    return True
                except:
                    # æœ€åé™çº§åˆ°æ¨¡æ‹Ÿæ’­æ”¾
                    self._simulate_speech(text)
                    return False
        except Exception as e:
            logger.error(f"LocalAI TTSæ‰§è¡Œå¤±è´¥: {e}")
            # å°è¯•é™çº§åˆ°æ¨¡æ‹Ÿæ’­æ”¾
            self._simulate_speech(text)
            return False
    
    def _speak_with_edge_tts(self, text: str) -> bool:
        obs_controller.set_text_source_content("textai123",text)
        """ä½¿ç”¨Edge TTSè¿›è¡Œè¯­éŸ³åˆæˆå¹¶æ’­æ”¾"""
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜éŸ³é¢‘
            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
                temp_file_path = temp_file.name
            
            # ä½¿ç”¨Edge TTSç”ŸæˆéŸ³é¢‘
            logger.info(f"ä½¿ç”¨Edge TTSç”Ÿæˆè¯­éŸ³ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}å­—ç¬¦ï¼Œè¯­éŸ³: {self.edge_tts_voice}")
            
            # è°ƒç”¨Edge TTSåˆæˆè¯­éŸ³
            communicate = edge_tts.Communicate(text, self.edge_tts_voice)
            logger.debug(f"Edge TTSé…ç½®: rate={self.edge_tts_rate}, volume={self.edge_tts_volume}")
            communicate.save_sync(temp_file_path)
            logger.info(f"Edge TTSéŸ³é¢‘ç”ŸæˆæˆåŠŸï¼Œæ–‡ä»¶è·¯å¾„: {temp_file_path}")
            
            # æ’­æ”¾éŸ³é¢‘
            pygame.mixer.music.load(temp_file_path)
            pygame.mixer.music.play()
            
            # ç­‰å¾…æ’­æ”¾å®Œæˆ
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
            
            return True
        except Exception as e:
            logger.error(f"Edge TTSæ‰§è¡Œå¤±è´¥: {e}")
            # å°è¯•é™çº§åˆ°Windowsè¯­éŸ³API
            self._tts_type = "windows"
            try:
                self.voice_engine = comtypes.client.CreateObject("SAPI.SpVoice")
                self.voice_engine.Speak(text)
                return True
            except:
                # æœ€åé™çº§åˆ°æ¨¡æ‹Ÿæ’­æ”¾
                self._simulate_speech(text)
                return False
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                except:
                    pass
    
    async def speak_async(self, text: str) -> threading.Thread:
        """å¼‚æ­¥æ’­æ”¾æ–‡æœ¬"""
        thread = threading.Thread(target=self.speak, args=(text,), daemon=True)
        thread.start()
        return thread
    
    def is_speaking_now(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾è¯­éŸ³"""
        with self._lock:
            return self._is_speaking
    
    def stop(self):
        """åœæ­¢å½“å‰æ’­æ”¾"""
        with self._lock:
            if self._is_speaking:
                try:
                    if self._tts_type == "windows" and self.voice_engine:
                        self.voice_engine.Speak(None, 3)  # SVSFPurgeBeforeSpeak
                    elif pygame.mixer.music.get_busy():
                        pygame.mixer.music.stop()
                    self._is_speaking = False
                    logger.info("TTSæ’­æ”¾å·²åœæ­¢")
                except Exception as e:
                    logger.error(f"åœæ­¢æ’­æ”¾æ—¶å‡ºé”™: {e}")
    
    def _simulate_speech(self, text: str):
        """æ¨¡æ‹Ÿè¯­éŸ³æ’­æ”¾ï¼ˆå½“å…¶ä»–æ–¹æ³•éƒ½å¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆï¼‰"""
        logger.warning("ä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³æ’­æ”¾")
        # ç®€å•æ¨¡æ‹Ÿè¯­éŸ³æ’­æ”¾çš„æ—¶é—´
        simulated_time = len(text) * 0.05  # å‡è®¾æ¯ä¸ªå­—ç¬¦éœ€è¦0.05ç§’
        time.sleep(min(simulated_time, 5))  # æœ€å¤šæ¨¡æ‹Ÿ5ç§’
    
    def set_tts_type(self, tts_type: str):
        """è®¾ç½®TTSç±»å‹"""
        if tts_type in ["windows", "localai", "edge", "custom"]:
            with self._lock:
                self._tts_type = tts_type
                logger.info(f"TTSç±»å‹å·²åˆ‡æ¢ä¸º: {tts_type}")
                # é‡æ–°åˆå§‹åŒ–
                if self.is_initialized:
                    if tts_type == "custom":
                        self.use_custom_voice_model()
                    else:
                        self.initialize(self.current_voice)
        else:
            logger.error(f"ä¸æ”¯æŒçš„TTSç±»å‹: {tts_type}")
    
    def get_tts_type(self) -> str:
        """è·å–å½“å‰TTSç±»å‹"""
        return self._tts_type

# å•ä¾‹å®ä¾‹
_tts_speaker_instance = None


def get_tts_speaker() -> TTSSpeaker:
    """è·å–TTSè¯´è¯å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _tts_speaker_instance
    if _tts_speaker_instance is None:
        _tts_speaker_instance = TTSSpeaker()
    return _tts_speaker_instance


# æµ‹è¯•ä»£ç ï¼ˆå½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰§è¡Œï¼‰
if __name__ == "__main__":
    print("æµ‹è¯•TTSè¯´è¯å™¨...")
    
    # è·å–TTSå®ä¾‹
    tts = get_tts_speaker()
    
    # åˆå§‹åŒ–TTS
    initialized = tts.initialize("zh-CN-XiaoxiaoNeural")
    
    if initialized:
        print(f"TTSåˆå§‹åŒ–æˆåŠŸï¼Œå½“å‰ä½¿ç”¨: {tts.get_tts_type()}")
        
        # æµ‹è¯•æ–‡æœ¬
        test_text = "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªTTSæµ‹è¯•ã€‚æˆ‘å¯ä»¥å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ã€‚"
        
        # æµ‹è¯•åŒæ­¥æ’­æ”¾
        print("æµ‹è¯•åŒæ­¥æ’­æ”¾...")
        tts.speak(test_text)
        
        # æµ‹è¯•å¼‚æ­¥æ’­æ”¾
        print("æµ‹è¯•å¼‚æ­¥æ’­æ”¾...")
        asyncio.run(tts.speak_async("è¿™æ˜¯å¼‚æ­¥æ’­æ”¾æµ‹è¯•ã€‚"))
        
        # ç­‰å¾…å¼‚æ­¥æ’­æ”¾å®Œæˆ
        time.sleep(3)
        
        # å¦‚æœå½“å‰ä¸æ˜¯Edge TTSï¼Œå°è¯•åˆ‡æ¢åˆ°Edge TTS
        if tts.get_tts_type() != "edge":
            print("\nå°è¯•åˆ‡æ¢åˆ°Edge TTS...")
            tts.set_tts_type("edge")
            if tts.is_initialized:
                print("Edge TTSåˆå§‹åŒ–æˆåŠŸ")
                tts.speak("è¿™æ˜¯ä½¿ç”¨Edge TTSç”Ÿæˆçš„è¯­éŸ³ã€‚")
            else:
                print("Edge TTSåˆå§‹åŒ–å¤±è´¥ï¼Œä¿æŒä½¿ç”¨å½“å‰TTS")
        
        # å¦‚æœå½“å‰ä¸æ˜¯LocalAI TTSï¼Œå°è¯•åˆ‡æ¢åˆ°LocalAI TTS
        if tts.get_tts_type() != "localai" and tts.get_tts_type() != "edge":
            print("\nå°è¯•åˆ‡æ¢åˆ°LocalAI TTS...")
            tts.set_tts_type("localai")
            if tts.is_initialized:
                print("LocalAI TTSåˆå§‹åŒ–æˆåŠŸ")
                tts.speak("è¿™æ˜¯ä½¿ç”¨LocalAIç”Ÿæˆçš„è¯­éŸ³ã€‚")
            else:
                print("LocalAI TTSåˆå§‹åŒ–å¤±è´¥ï¼Œä¿æŒä½¿ç”¨å½“å‰TTS")
        
        # å°è¯•åˆ‡æ¢åˆ°è‡ªå®šä¹‰TTSï¼ˆå¦‚æœæ”¯æŒï¼‰
        print("\nå°è¯•åˆ‡æ¢åˆ°è‡ªå®šä¹‰TTS...")
        tts.set_tts_type("custom")
        if tts.is_initialized:
            print("è‡ªå®šä¹‰TTSåˆå§‹åŒ–æˆåŠŸ")
            tts.speak("è¿™æ˜¯ä½¿ç”¨è‡ªå®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹ç”Ÿæˆçš„è¯­éŸ³ã€‚")
        else:
            print("è‡ªå®šä¹‰TTSåˆå§‹åŒ–å¤±è´¥ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶æˆ–æ¨¡å‹åŠ è½½å¤±è´¥")
    else:
        print("TTSåˆå§‹åŒ–å¤±è´¥")